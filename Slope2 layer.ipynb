{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\apisi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 413\u001b[0m\n\u001b[0;32m    410\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mlist\u001b[39m(net_u\u001b[38;5;241m.\u001b[39mparameters()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(net_v\u001b[38;5;241m.\u001b[39mparameters()), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m    412\u001b[0m fem_data_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFEM3_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 413\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_u\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfem_data_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfem_data_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# Load the best model\u001b[39;00m\n\u001b[0;32m    416\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 274\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net_u, net_v, optimizer, n_epochs, fem_data_file)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;241m<\u001b[39m best_loss:\n\u001b[0;32m    272\u001b[0m     best_loss \u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m    273\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave({\n\u001b[1;32m--> 274\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet_u_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mnet_u\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet_v_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: net_v\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: optimizer\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: loss,\n\u001b[0;32m    278\u001b[0m     }, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, LR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\apisi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1845\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[1;34m(self, destination, prefix, keep_vars, *args)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;66;03m# TODO: Change `*args` to `*` and remove the corresponding warning in docs when BC allows.\u001b[39;00m\n\u001b[0;32m   1844\u001b[0m \u001b[38;5;66;03m# Also remove the logic for arg parsing together.\u001b[39;00m\n\u001b[1;32m-> 1845\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstate_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, destination\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, keep_vars\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return a dictionary containing references to the whole state of the module.\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m \n\u001b[0;32m   1848\u001b[0m \u001b[38;5;124;03m    Both parameters and persistent buffers (e.g. running averages) are\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1887\u001b[0m \n\u001b[0;32m   1888\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1889\u001b[0m     \u001b[38;5;66;03m# TODO: Remove `args` and the parsing logic when BC allows.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.path import Path\n",
    "import pandas as pd\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set default tensor type to float32\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "# Define the neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden1 = nn.Linear(2, 64)\n",
    "        self.hidden2 = nn.Linear(64, 128)\n",
    "        self.hidden3 = nn.Linear(128, 256)\n",
    "        self.hidden4 = nn.Linear(256, 128)\n",
    "        self.hidden5 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.hidden1(x))\n",
    "        x = torch.tanh(self.hidden2(x))\n",
    "        x = torch.tanh(self.hidden3(x))\n",
    "        x = torch.tanh(self.hidden4(x))\n",
    "        x = torch.tanh(self.hidden5(x))\n",
    "        return self.output(x)\n",
    "\n",
    "# Define the problem domain using the given vertices\n",
    "vertices_layer1 = np.array([\n",
    "    [0, 0],\n",
    "    [0, 2],\n",
    "    [13, 2],\n",
    "    [13, 0],\n",
    "    [0, 0]  # Closing the polygon\n",
    "], dtype=np.float32)\n",
    "\n",
    "vertices_layer2 = np.array([\n",
    "    [0, 2],\n",
    "    [0, 4],\n",
    "    [4, 4],\n",
    "    [8, 2],\n",
    "    [0, 2]  # Closing the polygon\n",
    "], dtype=np.float32)\n",
    "\n",
    "path_layer1 = Path(vertices_layer1)\n",
    "path_layer2 = Path(vertices_layer2)\n",
    "\n",
    "def in_domain(x, y):\n",
    "    points = np.column_stack((x.detach().cpu().numpy(), y.detach().cpu().numpy()))\n",
    "    in_layer1 = torch.tensor(path_layer1.contains_points(points), dtype=torch.bool, device=device)\n",
    "    in_layer2 = torch.tensor(path_layer2.contains_points(points), dtype=torch.bool, device=device)\n",
    "    return in_layer1 | in_layer2\n",
    "\n",
    "def in_layer1(x, y):\n",
    "    points = np.column_stack((x.detach().cpu().numpy(), y.detach().cpu().numpy()))\n",
    "    return torch.tensor(path_layer1.contains_points(points), dtype=torch.bool, device=device)\n",
    "\n",
    "def in_layer2(x, y):\n",
    "    points = np.column_stack((x.detach().cpu().numpy(), y.detach().cpu().numpy()))\n",
    "    return torch.tensor(path_layer2.contains_points(points), dtype=torch.bool, device=device)\n",
    "\n",
    "# Define boundary conditions\n",
    "# Define boundary conditions\n",
    "def BC_bottom(x, y):\n",
    "    return ((y <= 0.1) & (x >= 0) & (x <= 13)).squeeze()\n",
    "\n",
    "def BC_left(x, y):\n",
    "    return ((x <= 0.1) & (y >= 0) & (y <= 4)).squeeze()\n",
    "\n",
    "def BC_top(x, y):\n",
    "    return (((y >= 3.9) & (x >= 0) & (x <= 4)) | \n",
    "            ((y >= -0.5 * x + 6 - 0.1) & (y <= -0.5 * x + 6 + 0.1) & (x > 4) & (x < 8)) | ((y == 2) & (x >= 8) &(x<=13))).squeeze()\n",
    "\n",
    "def BC_right(x, y):\n",
    "    return ((x >= 12.9) & (y >= 0) & (y <= 2)).squeeze()\n",
    "\n",
    "def smooth_heaviside(x, k=10):\n",
    "    return 1 / (1 + torch.exp(-k * x))\n",
    "\n",
    "def sigmoid_transition(x, k=10):\n",
    "    return torch.sigmoid(k * x)\n",
    "\n",
    "def atan_transition(x, k=1):\n",
    "    return 0.5 + torch.atan(k * x) / torch.pi\n",
    "\n",
    "def tanh_transition(y, transition_height=2.0, k=0.1):\n",
    "    return 0.5 * (1 + torch.tanh(k * (y - transition_height)))\n",
    "\n",
    "def calculate_E(y, E1=5, E2=2, k=0.1):\n",
    "    transition = tanh_transition(y, k=k)\n",
    "    return E1 * (1 - transition) + E2 * transition\n",
    "\n",
    "\n",
    "def BC(xy, net_u, net_v):\n",
    "    x, y = xy[:, 0].unsqueeze(1), xy[:, 1].unsqueeze(1)\n",
    "    \n",
    "    u = net_u(xy)\n",
    "    v = net_v(xy)\n",
    "    \n",
    "    bc_b = BC_bottom(x, y)\n",
    "    bc_l = BC_left(x, y)\n",
    "    bc_t = BC_top(x, y)\n",
    "    bc_r = BC_right(x, y)\n",
    "    \n",
    "    loss = torch.mean(u[bc_b]**2 + v[bc_b]**2)  # ux = uy = 0 on bottom\n",
    "    loss += torch.mean(u[bc_l]**2)  # ux = 0 on left side\n",
    "    loss += torch.mean(u[bc_r]**2)  # ux = 0 on right side\n",
    "    \n",
    "    # Stress-free condition at the top (σxx = 0, σyy = 0, σxy = 0)\n",
    "    xy_top = xy[bc_t].requires_grad_(True)\n",
    "    u_top = net_u(xy_top)\n",
    "    v_top = net_v(xy_top)\n",
    "    \n",
    "    u_x_top = torch.autograd.grad(u_top.sum(), xy_top, create_graph=True)[0][:, 0]\n",
    "    u_y_top = torch.autograd.grad(u_top.sum(), xy_top, create_graph=True)[0][:, 1]\n",
    "    v_x_top = torch.autograd.grad(v_top.sum(), xy_top, create_graph=True)[0][:, 0]\n",
    "    v_y_top = torch.autograd.grad(v_top.sum(), xy_top, create_graph=True)[0][:, 1]\n",
    "    \n",
    "    nu = 0.3  # Poisson's ratio\n",
    "    \n",
    "    # Calculate E using the new calculate_E function\n",
    "    E_top = calculate_E(xy_top[:, 1])\n",
    "    \n",
    "    sigma_xx_top = E_top / (1 - nu**2) * (u_x_top + nu * v_y_top)\n",
    "    sigma_yy_top = E_top / (1 - nu**2) * (v_y_top + nu * u_x_top)\n",
    "    sigma_xy_top = E_top / (2 * (1 + nu)) * (u_y_top + v_x_top)\n",
    "    loss += torch.mean(sigma_xx_top**2 + sigma_yy_top**2 + sigma_xy_top**2)\n",
    "    \n",
    "    # Stress-free condition at the right (σxy = 0)\n",
    "    xy_right = xy[bc_r].requires_grad_(True)\n",
    "    u_right = net_u(xy_right)\n",
    "    v_right = net_v(xy_right)\n",
    "    \n",
    "    u_y_right = torch.autograd.grad(u_right.sum(), xy_right, create_graph=True)[0][:, 1]\n",
    "    v_x_right = torch.autograd.grad(v_right.sum(), xy_right, create_graph=True)[0][:, 0]\n",
    "    \n",
    "    # Calculate E using the new calculate_E function for right boundary\n",
    "    E_right = calculate_E(xy_right[:, 1])\n",
    "    \n",
    "    sigma_xy_right = E_right / (2 * (1 + nu)) * (u_y_right + v_x_right)\n",
    "    loss += torch.mean(sigma_xy_right**2)\n",
    "    \n",
    "    # Stress-free condition at the left (σxy = 0)\n",
    "    xy_left = xy[bc_l].requires_grad_(True)\n",
    "    u_left = net_u(xy_left)\n",
    "    v_left = net_v(xy_left)\n",
    "\n",
    "    u_y_left = torch.autograd.grad(u_left.sum(), xy_left, create_graph=True)[0][:, 1]\n",
    "    v_x_left = torch.autograd.grad(v_left.sum(), xy_left, create_graph=True)[0][:, 0]\n",
    "\n",
    "# Calculate E using the new calculate_E function for left boundary\n",
    "    E_left = calculate_E(xy_left[:, 1])\n",
    "\n",
    "    sigma_xy_left = E_left / (2 * (1 + nu)) * (u_y_left + v_x_left)\n",
    "    loss += torch.mean(sigma_xy_left**2)    \n",
    "\n",
    "    return loss\n",
    "\n",
    "def load_fem_data(filename='FEM3_data.csv'):\n",
    "    df = pd.read_csv(filename)\n",
    "    x = torch.tensor(df['X'].values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "    y = torch.tensor(df['Y'].values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "    return x, y\n",
    "\n",
    "# Generate training data\n",
    "def generate_training_data(fem_data_file, n_boundary):\n",
    "    x, y = load_fem_data(fem_data_file)\n",
    "    \n",
    "    # Keep only points inside the domain\n",
    "    mask = in_domain(x, y)\n",
    "    x, y = x[mask], y[mask]\n",
    "    \n",
    "    # Generate boundary points\n",
    "    t = torch.linspace(0, 1, n_boundary, device=device).unsqueeze(1)\n",
    "    \n",
    "    # Define the boundary segments\n",
    "    segments = [\n",
    "        ([0, 0, 0], [0, 4, 4]),  # Left boundary\n",
    "        ([0, 4, 8, 13, 13], [4, 4, 2, 2, 0]),  # Top and right boundary\n",
    "        ([13, 0], [0, 0])  # Bottom boundary\n",
    "    ]\n",
    "    \n",
    "    x_b = []\n",
    "    y_b = []\n",
    "    \n",
    "    for segment in segments:\n",
    "        x_seg = torch.tensor(np.interp(t.cpu().numpy(), np.linspace(0, 1, len(segment[0])), segment[0]), dtype=torch.float32, device=device)\n",
    "        y_seg = torch.tensor(np.interp(t.cpu().numpy(), np.linspace(0, 1, len(segment[1])), segment[1]), dtype=torch.float32, device=device)\n",
    "        x_b.append(x_seg)\n",
    "        y_b.append(y_seg)\n",
    "    \n",
    "    x_b = torch.cat(x_b)\n",
    "    y_b = torch.cat(y_b)\n",
    "    \n",
    "    return x, y, x_b, y_b\n",
    "\n",
    "def smooth_heaviside(x, k=10):\n",
    "    return 1 / (1 + torch.exp(-k * x))\n",
    "\n",
    "def PDE(x, y, net_u, net_v):\n",
    "    xy = torch.cat([x, y], dim=1)\n",
    "    xy.requires_grad = True\n",
    "    \n",
    "    u = net_u(xy)\n",
    "    v = net_v(xy)\n",
    "    \n",
    "    u_x = torch.autograd.grad(u.sum(), xy, create_graph=True)[0][:, 0].unsqueeze(1)\n",
    "    u_y = torch.autograd.grad(u.sum(), xy, create_graph=True)[0][:, 1].unsqueeze(1)\n",
    "    v_x = torch.autograd.grad(v.sum(), xy, create_graph=True)[0][:, 0].unsqueeze(1)\n",
    "    v_y = torch.autograd.grad(v.sum(), xy, create_graph=True)[0][:, 1].unsqueeze(1)\n",
    "    \n",
    "    nu = 0.3  # Poisson's ratio\n",
    "    gamma = 1.8\n",
    "    \n",
    "    # ใช้ calculate_E ที่ปรับปรุงแล้ว\n",
    "    E = calculate_E(y)\n",
    "    \n",
    "    # คำนวณ stress ด้วย E ที่เปลี่ยนแปลงแบบฉับพลัน\n",
    "    sigma_xx = E / (1 - nu**2) * (u_x + nu * v_y)\n",
    "    sigma_yy = E / (1 - nu**2) * (v_y + nu * u_x)\n",
    "    sigma_xy = E / (2 * (1 + nu)) * (u_y + v_x)\n",
    "    \n",
    "    f_x = torch.zeros_like(x)\n",
    "    f_y = -gamma * torch.ones_like(y)  # Body force\n",
    "    \n",
    "    R_x = torch.autograd.grad(sigma_xx.sum(), xy, create_graph=True)[0][:, 0].unsqueeze(1) + \\\n",
    "          torch.autograd.grad(sigma_xy.sum(), xy, create_graph=True)[0][:, 1].unsqueeze(1) + f_x\n",
    "    R_y = torch.autograd.grad(sigma_xy.sum(), xy, create_graph=True)[0][:, 0].unsqueeze(1) + \\\n",
    "          torch.autograd.grad(sigma_yy.sum(), xy, create_graph=True)[0][:, 1].unsqueeze(1) + f_y\n",
    "    \n",
    "    loss_x = torch.mean(R_x**2)\n",
    "    loss_y = torch.mean(R_y**2)\n",
    "    \n",
    "    return loss_x, loss_y\n",
    "\n",
    "def train(net_u, net_v, optimizer, n_epochs, fem_data_file):\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=500, verbose=True)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x, y, x_b, y_b = generate_training_data(fem_data_file, 30000)\n",
    "        xy = torch.cat([x, y], dim=1)\n",
    "        xy_b = torch.cat([x_b, y_b], dim=1)\n",
    "        \n",
    "        loss_pde_x, loss_pde_y = PDE(x, y, net_u, net_v)\n",
    "        loss_bc = BC(xy_b, net_u, net_v)\n",
    "        \n",
    "        loss = loss_pde_x + 2 * loss_pde_y +loss_bc\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(list(net_u.parameters()) + list(net_v.parameters()), max_norm=0.5)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step(loss)\n",
    "        \n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save({\n",
    "                'net_u_state_dict': net_u.state_dict(),\n",
    "                'net_v_state_dict': net_v.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "            }, 'best_model.pth')\n",
    "        \n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch {epoch+1}/{n_epochs}, Loss: {loss.item():.6f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "\n",
    "def plot_results(net_u, net_v, fem_data_file='FEM3_data.csv', output_filename='PiNN3_data.csv'):\n",
    "    # Load FEM data\n",
    "    df_fem = pd.read_csv(fem_data_file)\n",
    "    X = df_fem['X'].values\n",
    "    Y = df_fem['Y'].values\n",
    "    \n",
    "    # Create tensor from FEM data\n",
    "    XY = torch.tensor(np.column_stack([X, Y]), dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Compute displacements and stresses for all points\n",
    "    XY.requires_grad_(True)\n",
    "    with torch.enable_grad():\n",
    "        U = net_u(XY)\n",
    "        V = net_v(XY)\n",
    "        \n",
    "        U_x = torch.autograd.grad(U.sum(), XY, create_graph=True)[0][:, 0]\n",
    "        U_y = torch.autograd.grad(U.sum(), XY, create_graph=True)[0][:, 1]\n",
    "        V_x = torch.autograd.grad(V.sum(), XY, create_graph=True)[0][:, 0]\n",
    "        V_y = torch.autograd.grad(V.sum(), XY, create_graph=True)[0][:, 1]\n",
    "        \n",
    "        nu = 0.3  # Poisson's ratio\n",
    "        \n",
    "        # Calculate E using the calculate_E function\n",
    "        E = calculate_E(XY[:, 1])\n",
    "        \n",
    "        # Calculate stresses using the variable E\n",
    "        sigma_xx = E / (1 - nu**2) * (U_x + nu * V_y)\n",
    "        sigma_yy = E / (1 - nu**2) * (V_y + nu * U_x)\n",
    "        sigma_xy = E / (2 * (1 + nu)) * (U_y + V_x)\n",
    "    \n",
    "    # Move tensors to CPU, detach from computation graph, and convert to numpy\n",
    "    U_full = U.detach().cpu().numpy().squeeze()/1000\n",
    "    V_full = V.detach().cpu().numpy().squeeze()/1000 \n",
    "    sigma_xx_full = sigma_xx.detach().cpu().numpy().squeeze() * 10\n",
    "    sigma_yy_full = sigma_yy.detach().cpu().numpy().squeeze() * 10\n",
    "    sigma_xy_full = sigma_xy.detach().cpu().numpy().squeeze() * 10\n",
    "    \n",
    "    # Calculate displacement magnitude\n",
    "    magnitude = np.sqrt(U_full**2 + V_full**2)\n",
    "    # Create DataFrame for CSV export\n",
    "    df_out = pd.DataFrame({\n",
    "        'X': X,\n",
    "        'Y': Y,\n",
    "        'ux': U_full,\n",
    "        'uy': V_full,\n",
    "        'sigma_xx': sigma_xx_full,\n",
    "        'sigma_yy': sigma_yy_full,\n",
    "        'sigma_xy': sigma_xy_full,\n",
    "        'magnitude': magnitude\n",
    "    })\n",
    "\n",
    "    # Save the output to a CSV file\n",
    "    df_out.to_csv(output_filename, index=False)\n",
    "    print(f\"Results saved to {output_filename}\")\n",
    "    \n",
    "    # Apply domain mask for plotting\n",
    "    mask = in_domain(XY[:, 0], XY[:, 1])\n",
    "    mask_cpu = mask.detach().cpu().numpy()\n",
    "    \n",
    "    # Create masked arrays for plotting\n",
    "    U_masked = np.ma.masked_array(U_full, mask=~mask_cpu)\n",
    "    V_masked = np.ma.masked_array(V_full, mask=~mask_cpu)\n",
    "    sigma_xx_masked = np.ma.masked_array(sigma_xx_full, mask=~mask_cpu)\n",
    "    sigma_yy_masked = np.ma.masked_array(sigma_yy_full, mask=~mask_cpu)\n",
    "    sigma_xy_masked = np.ma.masked_array(sigma_xy_full, mask=~mask_cpu)\n",
    "    magnitude_masked = np.ma.masked_array(magnitude, mask=~mask_cpu)\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # Plot u displacement (ux)\n",
    "    plt.subplot(231)\n",
    "    sc = plt.scatter(X, Y, c=U_masked, cmap='jet')\n",
    "    plt.colorbar(sc, label='ux displacement')\n",
    "    plt.title('ux displacement')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    \n",
    "    # Plot v displacement (uy)\n",
    "    plt.subplot(232)\n",
    "    sc = plt.scatter(X, Y, c=V_masked, cmap='jet')\n",
    "    plt.colorbar(sc, label='uy displacement')\n",
    "    plt.title('uy displacement')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    \n",
    "    # Plot sigma_xx\n",
    "    plt.subplot(233)\n",
    "    sc = plt.scatter(X, Y, c=sigma_xx_masked, cmap='jet')\n",
    "    plt.colorbar(sc, label='sigma_xx')\n",
    "    plt.title('sigma_xx')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    \n",
    "    # Plot sigma_yy\n",
    "    plt.subplot(234)\n",
    "    sc = plt.scatter(X, Y, c=sigma_yy_masked, cmap='jet')\n",
    "    plt.colorbar(sc, label='sigma_yy')\n",
    "    plt.title('sigma_yy')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    \n",
    "    # Plot sigma_xy\n",
    "    plt.subplot(235)\n",
    "    sc = plt.scatter(X, Y, c=sigma_xy_masked, cmap='jet')\n",
    "    plt.colorbar(sc, label='sigma_xy')\n",
    "    plt.title('sigma_xy')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    \n",
    "    # Plot displacement magnitude\n",
    "    plt.subplot(236)\n",
    "    sc = plt.scatter(X, Y, c=magnitude_masked, cmap='jet')\n",
    "    plt.colorbar(sc, label='Displacement magnitude')\n",
    "    plt.title('Displacement magnitude')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('PiNN_results.png')\n",
    "    plt.show()\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    net_u = Net().to(device)\n",
    "    net_v = Net().to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(list(net_u.parameters()) + list(net_v.parameters()), lr=0.001)\n",
    "    \n",
    "    fem_data_file = 'FEM3_data.csv'\n",
    "    train(net_u, net_v, optimizer, n_epochs=2000, fem_data_file=fem_data_file)\n",
    "    \n",
    "    # Load the best model\n",
    "    checkpoint = torch.load('best_model.pth')\n",
    "    net_u.load_state_dict(checkpoint['net_u_state_dict'])\n",
    "    net_v.load_state_dict(checkpoint['net_v_state_dict'])\n",
    "    \n",
    "    try:\n",
    "        plot_results(net_u, net_v, fem_data_file=fem_data_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in plot_results: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
